{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation from Train video\n",
    "1. First check if the files are in Google Drive; if so, then just copy from there (maybe)\n",
    "1. Generate JPG images from MP4 file and move to \"original/images\"\n",
    "2. Generate TXT labels from train_mot_.txt and move to \"valid/labels\"\n",
    "3. Separate into Train, Validation and Test datasets\n",
    "\n",
    "TODO\n",
    "- Consider resizing to 640x640 images (also see this post about possible problems with this)\n",
    "    - https://github.com/ultralytics/ultralytics/issues/4510\n",
    "- Remove valid images after copying to train,valid,test folders\n",
    "- Add number of frames to dataset root folder to experiment with lower number of frames\n",
    "- Improve the format of the image names (maybe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pip packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.1\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.0.216-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from ultralytics) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from ultralytics) (1.24.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from ultralytics) (2.28.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from ultralytics) (1.10.1)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Downloading torch-2.1.1-cp38-cp38-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Downloading torchvision-0.16.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from ultralytics) (4.66.1)\n",
      "Collecting pandas>=1.1.4 (from ultralytics)\n",
      "  Using cached pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Downloading seaborn-0.13.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: psutil in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from ultralytics) (5.9.4)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting thop>=0.1.1 (from ultralytics)\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from matplotlib>=3.3.0->ultralytics) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from matplotlib>=3.3.0->ultralytics) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from matplotlib>=3.3.0->ultralytics) (5.10.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Collecting tzdata>=2022.1 (from pandas>=1.1.4->ultralytics)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from requests>=2.23.0->ultralytics) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Collecting filelock (from torch>=1.8.0->ultralytics)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Collecting sympy (from torch>=1.8.0->ultralytics)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch>=1.8.0->ultralytics)\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Collecting fsspec (from torch>=1.8.0->ultralytics)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /work/marioeduardo-a/.local/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /work/marioeduardo-a/miniconda3/envs/ftc38/lib/python3.8/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.8.0->ultralytics)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics-8.0.216-py3-none-any.whl (645 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.7/645.7 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "Downloading seaborn-0.13.0-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.1-cp38-cp38-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.1-cp38-cp38-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py-cpuinfo, mpmath, tzdata, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, seaborn, nvidia-cusolver-cu12, torch, torchvision, thop, ultralytics\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.10.0 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 pandas-2.0.3 py-cpuinfo-9.0.0 seaborn-0.13.0 sympy-1.12 thop-0.1.1.post2209072238 torch-2.1.1 torchvision-0.16.1 triton-2.1.0 tzdata-2023.3 ultralytics-8.0.216\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install ultralytics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filenames definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "data = '/work/marioeduardo-a/ftc'\n",
    "images=os.path.join(data,\"images\")\n",
    "labels=os.path.join(data,\"labels\")\n",
    "\n",
    "images_original = os.path.join(images,'original')\n",
    "labels_original = os.path.join(labels,'original')\n",
    "\n",
    "images_train = os.path.join(images,'train')\n",
    "labels_train = os.path.join(labels,'train')\n",
    "\n",
    "images_valid = os.path.join(images,'valid')\n",
    "labels_valid = os.path.join(labels,'valid')\n",
    "\n",
    "images_test = os.path.join(images,'test')\n",
    "labels_test = os.path.join(labels,'test')\n",
    "\n",
    "\n",
    "video_train=os.path.join(data,'FTC-2024-data/Train/train.mp4')\n",
    "labels_train_file=os.path.join(data,'FTC-2024-data/Train/train_gt_mot.txt')\n",
    "# video_development=os.path.join(data,'FTC-2024-data/Development/development.mp4')\n",
    "# video_test=os.path.join(data,'FTC-2024-data/Test/test.mp4')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate original images from mp4 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 10000/10000 [12:08<00:00, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images outputed: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Copy images from drive ioriginalf they exist there\n",
    "if not os.path.exists(images_original):\n",
    "    os.makedirs(images_original)\n",
    "\n",
    "    capture = cv2.VideoCapture(video_train)\n",
    "    total_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # total_frames=100\n",
    "\n",
    "    for f in tqdm(range(1,total_frames+1)):\n",
    "        _,frame=capture.read()\n",
    "        cv2.imwrite(os.path.join(images_original,str(f).zfill(6)+\".jpg\"),frame, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "        # cv2.imwrite(newPath, frame, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "        # cv2.imencode('.jpg', frame)[1].tofile(newPath)\n",
    "\n",
    "    capture.release()\n",
    "    #print(\"Last frame number: \" + str(frames - 1))\n",
    "    print(\"Images outputed: \" + str(len(os.listdir(images_original))))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract labels into each frames to label_foler\n",
    "\n",
    "if not os.path.exists(labels_original):\n",
    "    video_width = 0\n",
    "    video_height = 0\n",
    "    cap = cv2.VideoCapture(video_train)\n",
    "    if cap.isOpened():\n",
    "        video_width  = cap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "        video_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "    cap.release()\n",
    "\n",
    "    print(\"Video width: \" + str(video_width))\n",
    "    print(\"Video height: \" + str(video_height))\n",
    "\n",
    "    \n",
    "    os.makedirs(labels_original)\n",
    "\n",
    "\n",
    "    print(\"Start translate labels into YOLO format.\")\n",
    "    print(\"Label source: \" + labels_train_file)\n",
    "    print(\"Label destnation: \" + labels_original)\n",
    "\n",
    "    current_frame = -1\n",
    "    with open(labels_train_file) as f:\n",
    "        current_file = 0\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            frame, bid, top, left, width, height, _, _, _, _ = line.split(\" \")\n",
    "            frame, bid, left, top, width, height = int(frame), int(bid), float(left), float(top), int(width), int(height)\n",
    "            center_x = left + width / 2\n",
    "            center_y = top + height/ 2\n",
    "            rel_center_x = center_x / video_width\n",
    "            rel_center_y = center_y / video_height\n",
    "            rel_width = width / video_width\n",
    "            rel_height = height / video_height\n",
    "            if frame != current_frame:\n",
    "                if current_file != 0:\n",
    "                    current_file.close()\n",
    "                if frame == total_frames + 1:\n",
    "                    break\n",
    "                current_file = open(os.path.join(labels_original, str(frame).zfill(6) + \".txt\"), 'w')\n",
    "            #current_file.write(\"class_id center_x center_y bbox_width bbox_height\\n\")\n",
    "            current_frame = frame\n",
    "            current_file.write(\"0 \" + str(rel_center_x) + \" \" + str(rel_center_y) + \" \" + str(rel_width) + \" \" + str(rel_height) + \"\\n\")\n",
    "\n",
    "        current_file.close()\n",
    "    print(\"Translation finished!\")\n",
    "    print(\"Last frame number: \" + str(current_frame))\n",
    "    print(\"Labels outputed: \" + str(len(os.listdir(labels_original))))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Valid Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_offset: 7500\n",
      "valid_offset: 9000\n",
      "test_offset: 10000\n",
      "\n",
      "len(train): 7500\n",
      "len(valid_ids): 1500\n",
      "len(train): 1000\n",
      "\n",
      "Train images:  7500\n",
      "Train labels:  7500\n",
      "Valid images:  1500\n",
      "Valid labels:  1500\n",
      "Test images:  1000\n",
      "Test labels:  1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "\n",
    "if not os.path.exists(images_train):\n",
    "    ids =[i for i in range(1,total_frames+1)]\n",
    "    random.shuffle(ids)\n",
    "\n",
    "    train_offset = int(0.75*total_frames)\n",
    "    valid_offset = int(train_offset+0.15*total_frames)\n",
    "    test_offset  = int(valid_offset+0.10*total_frames)\n",
    "    print(\"train_offset:\",train_offset)\n",
    "    print(\"valid_offset:\",valid_offset)\n",
    "    print(\"test_offset:\",test_offset)\n",
    "    print()\n",
    "    train_ids = ids[:train_offset]\n",
    "    valid_ids = ids[train_offset:valid_offset]\n",
    "    test_ids  = ids[valid_offset:]\n",
    "\n",
    "\n",
    "    print('len(train):',len(train_ids))\n",
    "    print('len(valid_ids):',len(valid_ids))\n",
    "    print('len(train):',len(test_ids))\n",
    "    print()\n",
    "    # Create folders\n",
    "    types=[images,labels]\n",
    "    folders=[\"train\",\"valid\",\"test\"]\n",
    "    \n",
    "\n",
    "    for t in types:\n",
    "        for ff in folders:\n",
    "            folder_fn = os.path.join(t,ff)\n",
    "            if not os.path.exists(folder_fn):\n",
    "                os.makedirs(folder_fn)\n",
    "\n",
    "    #move training set to image_train_folder and label_train_folder\n",
    "    for i in range(total_frames):\n",
    "        if i<train_offset:\n",
    "            destination_folder= \"train\"\n",
    "        elif i<valid_offset:\n",
    "            destination_folder= \"valid\"\n",
    "        else:\n",
    "            destination_folder= \"test\"\n",
    "        destination_images=os.path.join(images,destination_folder)\n",
    "        destination_labels=os.path.join(labels, destination_folder)\n",
    "\n",
    "        source      = os.path.join(images_original,str(ids[i]).zfill(6)+\".jpg\")\n",
    "        destination = os.path.join(destination_images,str(ids[i]).zfill(6)+\".jpg\")\n",
    "        shutil.copy(source, destination)\n",
    "\n",
    "        source      = os.path.join(labels_original,str(ids[i]).zfill(6)+\".txt\")\n",
    "        destination = os.path.join(destination_labels,str(ids[i]).zfill(6)+\".txt\")\n",
    "\n",
    "        shutil.copy(source, destination)\n",
    "\n",
    "\n",
    "    # Validate sizes of folders\n",
    "    #image count in colab vm\n",
    "    print(\"Train images: \",len(os.listdir(images_train)))\n",
    "    print(\"Train labels: \",len(os.listdir(labels_train)))\n",
    "    print(\"Valid images: \",len(os.listdir(images_valid)))\n",
    "    print(\"Valid labels: \",len(os.listdir(labels_valid)))\n",
    "    print(\"Test images: \",len(os.listdir(images_test)))\n",
    "    print(\"Test labels: \",len(os.listdir(labels_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images test\n",
      "000002.jpg\n",
      "000007.jpg\n",
      "000008.jpg\n",
      "ls: write error: Broken pipe\n",
      "labels test\n",
      "000002.txt\n",
      "000007.txt\n",
      "000008.txt\n",
      "ls: write error: Broken pipe\n",
      "\n",
      "images train\n",
      "000001.jpg\n",
      "000003.jpg\n",
      "000004.jpg\n",
      "ls: write error: Broken pipe\n",
      "labels train\n",
      "000001.txt\n",
      "000003.txt\n",
      "000004.txt\n",
      "ls: write error: Broken pipe\n",
      "\n",
      "images valid\n",
      "000010.jpg\n",
      "000019.jpg\n",
      "000022.jpg\n",
      "labels valid\n",
      "000010.txt\n",
      "000019.txt\n",
      "000022.txt\n",
      "ls: write error: Broken pipe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for qq in ['test','train','valid']:\n",
    "    for tt in ['images','labels']:\n",
    "        print(tt,qq)\n",
    "        # print('bef')\n",
    "        !ls -1 /work/marioeduardo-a/ftc/{tt}/{qq} | head -n 3\n",
    "        # print('aft')\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4fe87f46699e893a0acb7d4a87394b12f942f41fa1b24f2bcaf86378d3ff87d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
